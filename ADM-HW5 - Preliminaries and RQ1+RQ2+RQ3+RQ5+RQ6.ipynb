{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the datasets and manage the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>1185516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>1059989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>1062426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>1161925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>541222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source     dest\n",
       "0      95  1185516\n",
       "1     108  1059989\n",
       "2     108  1062426\n",
       "3     108  1161925\n",
       "4     134   541222"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = pd.read_csv(\"wikigraph_reduced.csv\", sep=\"\\t\", usecols = [\"0\", \"1\"])\n",
    "edges.columns = [\"source\", \"dest\"]\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the pages names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chiasmal syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kleroterion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pinakion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LyndonHochschildSerre spectral sequence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zariski's main theorem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791484</th>\n",
       "      <td>Noadiah Russell (Yale founder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791485</th>\n",
       "      <td>Cornus officinalis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791486</th>\n",
       "      <td>Peter Grummitt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791487</th>\n",
       "      <td>Baron Estcourt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791488</th>\n",
       "      <td>Catherine Dubosc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1791489 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name\n",
       "node                                            \n",
       "0                              Chiasmal syndrome\n",
       "1                                    Kleroterion\n",
       "2                                       Pinakion\n",
       "3        LyndonHochschildSerre spectral sequence\n",
       "4                         Zariski's main theorem\n",
       "...                                          ...\n",
       "1791484           Noadiah Russell (Yale founder)\n",
       "1791485                       Cornus officinalis\n",
       "1791486                           Peter Grummitt\n",
       "1791487                           Baron Estcourt\n",
       "1791488                         Catherine Dubosc\n",
       "\n",
       "[1791489 rows x 1 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_names = pd.read_csv(\"wiki-topcats-page-names.txt\", names=[\"node name\"])\n",
    "pages_names\n",
    "\n",
    "pages_names['node'] = [s.split()[0] for s in list(pages_names['node name']) ]\n",
    "pages_names['name'] = [' '.join(s.split()[1:]) for s in list(pages_names['node name'])]\n",
    "\n",
    "pages_names = pages_names.set_index(\"node\").drop('node name', axis=1)\n",
    "pages_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read each line of the \"wiki-topcats-categories.txt\" and create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Pages List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English_footballers</td>\n",
       "      <td>[22860, 28411, 28961, 28979, 29264, 29573, 295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The_Football_League_players</td>\n",
       "      <td>[14003, 23536, 27109, 27348, 27459, 27989, 280...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Association_football_forwards</td>\n",
       "      <td>[26876, 26877, 26879, 26887, 26892, 26904, 269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Association_football_midfielders</td>\n",
       "      <td>[14003, 15291, 23536, 26880, 26882, 26885, 268...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Association_football_defenders</td>\n",
       "      <td>[15217, 22860, 26873, 26878, 26881, 26898, 269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harvard_University_alumni</td>\n",
       "      <td>[77, 1013, 1271, 1663, 1779, 1843, 2212, 3193,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Major_League_Baseball_pitchers</td>\n",
       "      <td>[79, 24213, 33054, 37167, 53973, 63107, 69823,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Members_of_the_United_Kingdom_Parliament_for_E...</td>\n",
       "      <td>[29098, 29493, 29585, 30255, 30389, 30505, 306...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian_films</td>\n",
       "      <td>[1308, 29286, 53565, 70274, 70275, 70797, 1233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Year_of_death_missing</td>\n",
       "      <td>[98, 126, 227, 1823, 2170, 2223, 13215, 14003,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rivers_of_Romania</td>\n",
       "      <td>[72111, 72112, 72113, 72114, 72115, 72116, 721...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Main_Belt_asteroids</td>\n",
       "      <td>[13184, 13992, 22277, 23539, 29163, 33254, 334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Asteroids_named_for_people</td>\n",
       "      <td>[13184, 13992, 23539, 33990, 33991, 37535, 375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>English-language_films</td>\n",
       "      <td>[55, 134, 153, 214, 1083, 1084, 1087, 1089, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>American_films</td>\n",
       "      <td>[134, 153, 173, 1083, 1087, 1089, 1131, 1152, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>American_television_actors</td>\n",
       "      <td>[174, 938, 980, 1086, 1088, 1099, 1106, 1109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>American_film_actors</td>\n",
       "      <td>[174, 980, 1088, 1099, 1106, 1109, 1121, 1122,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Debut_albums</td>\n",
       "      <td>[95, 108, 112, 113, 190, 254, 1413, 1451, 1452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Black-and-white_films</td>\n",
       "      <td>[134, 16130, 19763, 26846, 31864, 35833, 38917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Year_of_birth_missing</td>\n",
       "      <td>[147, 171, 1056, 1656, 13215, 14003, 15293, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Place_of_birth_missing_(living_people)</td>\n",
       "      <td>[167, 1100, 1104, 1118, 1119, 1139, 1140, 1144...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Category  \\\n",
       "0                                 English_footballers   \n",
       "1                         The_Football_League_players   \n",
       "2                       Association_football_forwards   \n",
       "3                    Association_football_midfielders   \n",
       "4                      Association_football_defenders   \n",
       "5                           Harvard_University_alumni   \n",
       "6                      Major_League_Baseball_pitchers   \n",
       "7   Members_of_the_United_Kingdom_Parliament_for_E...   \n",
       "8                                        Indian_films   \n",
       "9                               Year_of_death_missing   \n",
       "10                                  Rivers_of_Romania   \n",
       "11                                Main_Belt_asteroids   \n",
       "12                         Asteroids_named_for_people   \n",
       "13                             English-language_films   \n",
       "14                                     American_films   \n",
       "15                         American_television_actors   \n",
       "16                               American_film_actors   \n",
       "17                                       Debut_albums   \n",
       "18                              Black-and-white_films   \n",
       "19                              Year_of_birth_missing   \n",
       "20             Place_of_birth_missing_(living_people)   \n",
       "\n",
       "                                           Pages List  \n",
       "0   [22860, 28411, 28961, 28979, 29264, 29573, 295...  \n",
       "1   [14003, 23536, 27109, 27348, 27459, 27989, 280...  \n",
       "2   [26876, 26877, 26879, 26887, 26892, 26904, 269...  \n",
       "3   [14003, 15291, 23536, 26880, 26882, 26885, 268...  \n",
       "4   [15217, 22860, 26873, 26878, 26881, 26898, 269...  \n",
       "5   [77, 1013, 1271, 1663, 1779, 1843, 2212, 3193,...  \n",
       "6   [79, 24213, 33054, 37167, 53973, 63107, 69823,...  \n",
       "7   [29098, 29493, 29585, 30255, 30389, 30505, 306...  \n",
       "8   [1308, 29286, 53565, 70274, 70275, 70797, 1233...  \n",
       "9   [98, 126, 227, 1823, 2170, 2223, 13215, 14003,...  \n",
       "10  [72111, 72112, 72113, 72114, 72115, 72116, 721...  \n",
       "11  [13184, 13992, 22277, 23539, 29163, 33254, 334...  \n",
       "12  [13184, 13992, 23539, 33990, 33991, 37535, 375...  \n",
       "13  [55, 134, 153, 214, 1083, 1084, 1087, 1089, 11...  \n",
       "14  [134, 153, 173, 1083, 1087, 1089, 1131, 1152, ...  \n",
       "15  [174, 938, 980, 1086, 1088, 1099, 1106, 1109, ...  \n",
       "16  [174, 980, 1088, 1099, 1106, 1109, 1121, 1122,...  \n",
       "17  [95, 108, 112, 113, 190, 254, 1413, 1451, 1452...  \n",
       "18  [134, 16130, 19763, 26846, 31864, 35833, 38917...  \n",
       "19  [147, 171, 1056, 1656, 13215, 14003, 15293, 22...  \n",
       "20  [167, 1100, 1104, 1118, 1119, 1139, 1140, 1144...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = pd.read_csv(\"wiki-topcats-categories.txt\", sep=\";\", names = [\"Category\", \"Pages List\"])\n",
    "categories[\"Category\"] = categories.Category.apply(lambda x: x[9:])\n",
    "categories[\"Pages List\"] = categories[\"Pages List\"].apply(lambda x: x.split())\n",
    "\n",
    "# Remove categories with length not in the range 5000 and 30000\n",
    "categories['Length'] = [len(x) for x in categories['Pages List']]\n",
    "\n",
    "# Removes the categories whose number of articles in less than 5000 and more than 30000.\n",
    "categories = categories.loc[(categories['Length']>=5000) & (categories['Length']<=30000)]\n",
    "del categories['Length']\n",
    "\n",
    "# reset index\n",
    "categories = categories.reset_index()\n",
    "del categories['index']\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that one article might belong to a single category or multiple ones. In the case of multiple appearance, you break the ties uniformly at random. Please, do it before solving any task in the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = list(categories[\"Category\"])\n",
    "pages_list = list(categories[\"Pages List\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a vocabulary in order to create the clean categories without replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {}\n",
    "for i, list_pages in enumerate(pages_list):\n",
    "    for node in list_pages:\n",
    "        if node not in nodes:\n",
    "            nodes[node] = []\n",
    "        nodes[node].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose uniformly at random a category where the page will be belong, then create the dictionary.\n",
    "\n",
    "Remove also the categories that haven't any node in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = set(edges[\"source\"])\n",
    "dests = set(edges[\"dest\"])\n",
    "red_nodes = sources.union(dests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "nodes2 = defaultdict(list)\n",
    "for node in nodes.keys():\n",
    "    cat = random.sample(nodes[node], 1)[0]\n",
    "    if int(node) in red_nodes:\n",
    "        nodes2[cat].append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>pages list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English_footballers</td>\n",
       "      <td>[28961, 48718, 72482, 72496, 72539, 72555, 725...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Association_football_forwards</td>\n",
       "      <td>[33973, 72536, 72546, 72696, 72708, 72914, 729...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Association_football_defenders</td>\n",
       "      <td>[48583, 72747, 72943, 73047, 73070, 73148, 731...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The_Football_League_players</td>\n",
       "      <td>[48730, 72488, 72532, 72545, 72563, 72569, 726...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Year_of_death_missing</td>\n",
       "      <td>[72528, 72589, 72591, 72861, 73069, 75258, 752...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Association_football_midfielders</td>\n",
       "      <td>[72567, 72580, 72862, 73109, 73252, 74371, 745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Year_of_birth_missing</td>\n",
       "      <td>[75306, 76428, 93668, 107488, 1197623, 1428187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Place_of_birth_missing_(living_people)</td>\n",
       "      <td>[81209, 82307, 84217, 93493, 1006344, 1298232,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Members_of_the_United_Kingdom_Parliament_for_E...</td>\n",
       "      <td>[535217, 536702, 536701, 538562, 538800, 53913...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harvard_University_alumni</td>\n",
       "      <td>[1663, 1843, 3260, 3431, 11386, 11858, 12295, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>American_film_actors</td>\n",
       "      <td>[143566, 154133, 244627, 343966, 351585, 42318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>American_television_actors</td>\n",
       "      <td>[301418, 400707, 419812, 469376, 744125, 74413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Major_League_Baseball_pitchers</td>\n",
       "      <td>[71163, 112694, 115217, 122453, 142660, 143175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Indian_films</td>\n",
       "      <td>[53565, 70274, 70275, 136154, 136155, 136157, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>English-language_films</td>\n",
       "      <td>[581028, 581089, 582580, 590294, 590356, 68070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>American_films</td>\n",
       "      <td>[582475, 1058236, 1087, 1089, 1152, 1158, 1267...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Black-and-white_films</td>\n",
       "      <td>[587697, 588219, 588536, 589113, 589167, 58930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Rivers_of_Romania</td>\n",
       "      <td>[72111, 72112, 72113, 72114, 72115, 72116, 721...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Main_Belt_asteroids</td>\n",
       "      <td>[13184, 13992, 22277, 23539, 33254, 33401, 359...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Asteroids_named_for_people</td>\n",
       "      <td>[33991, 39039, 96569, 96574, 96575, 103217, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Debut_albums</td>\n",
       "      <td>[95, 108, 31695, 31722, 31725, 31726, 31728, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             category  \\\n",
       "0                                 English_footballers   \n",
       "1                       Association_football_forwards   \n",
       "2                      Association_football_defenders   \n",
       "3                         The_Football_League_players   \n",
       "4                               Year_of_death_missing   \n",
       "5                    Association_football_midfielders   \n",
       "6                               Year_of_birth_missing   \n",
       "7              Place_of_birth_missing_(living_people)   \n",
       "8   Members_of_the_United_Kingdom_Parliament_for_E...   \n",
       "9                           Harvard_University_alumni   \n",
       "10                               American_film_actors   \n",
       "11                         American_television_actors   \n",
       "12                     Major_League_Baseball_pitchers   \n",
       "13                                       Indian_films   \n",
       "14                             English-language_films   \n",
       "15                                     American_films   \n",
       "16                              Black-and-white_films   \n",
       "17                                  Rivers_of_Romania   \n",
       "18                                Main_Belt_asteroids   \n",
       "19                         Asteroids_named_for_people   \n",
       "20                                       Debut_albums   \n",
       "\n",
       "                                           pages list  \n",
       "0   [28961, 48718, 72482, 72496, 72539, 72555, 725...  \n",
       "1   [33973, 72536, 72546, 72696, 72708, 72914, 729...  \n",
       "2   [48583, 72747, 72943, 73047, 73070, 73148, 731...  \n",
       "3   [48730, 72488, 72532, 72545, 72563, 72569, 726...  \n",
       "4   [72528, 72589, 72591, 72861, 73069, 75258, 752...  \n",
       "5   [72567, 72580, 72862, 73109, 73252, 74371, 745...  \n",
       "6   [75306, 76428, 93668, 107488, 1197623, 1428187...  \n",
       "7   [81209, 82307, 84217, 93493, 1006344, 1298232,...  \n",
       "8   [535217, 536702, 536701, 538562, 538800, 53913...  \n",
       "9   [1663, 1843, 3260, 3431, 11386, 11858, 12295, ...  \n",
       "10  [143566, 154133, 244627, 343966, 351585, 42318...  \n",
       "11  [301418, 400707, 419812, 469376, 744125, 74413...  \n",
       "12  [71163, 112694, 115217, 122453, 142660, 143175...  \n",
       "13  [53565, 70274, 70275, 136154, 136155, 136157, ...  \n",
       "14  [581028, 581089, 582580, 590294, 590356, 68070...  \n",
       "15  [582475, 1058236, 1087, 1089, 1152, 1158, 1267...  \n",
       "16  [587697, 588219, 588536, 589113, 589167, 58930...  \n",
       "17  [72111, 72112, 72113, 72114, 72115, 72116, 721...  \n",
       "18  [13184, 13992, 22277, 23539, 33254, 33401, 359...  \n",
       "19  [33991, 39039, 96569, 96574, 96575, 103217, 11...  \n",
       "20  [95, 108, 31695, 31722, 31725, 31726, 31728, 4...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_categories = pd.DataFrame()\n",
    "new_categories['category'] = nodes2.keys()\n",
    "new_categories['pages list'] = nodes2.values()\n",
    "\n",
    "def set_category(x, categories):\n",
    "    return categories.loc[x, \"Category\"]\n",
    "    \n",
    "new_categories[\"category\"] = new_categories.category.apply(lambda x: set_category(x, categories)) # set the category not the integer value\n",
    "new_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the graph G=(V, E), where V is the set of articles and E the hyperlinks among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the graph, first we consider if the edges dataframe contents a graph directed or not.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDirected(edges):\n",
    "    if len(set(list(edges['source'])).intersection(set(list(edges['dest'])))) > 0:\n",
    "        return \"directed\"\n",
    "    else:\n",
    "        return \"undirected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isDirected(edges) == \"directed\":\n",
    "    G = nx.DiGraph(directed=True)\n",
    "else:\n",
    "    G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = list(edges['source'])\n",
    "dests = list(edges['dest'])\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    G.add_node(sources[i], name = pages_names.loc[str(sources[i]), 'name']) # source\n",
    "    G.add_node(dests[i], name = pages_names.loc[str(dests[i]), 'name']) # dest\n",
    "    \n",
    "    G.add_edge(sources[i], dests[i], weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 98343\\nNumber of edges: 483094\\nAverage in degree:   4.9123\\nAverage out degree:   4.9123'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes is: 98343 and the number of edges is: 483094\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of nodes is: {G.number_of_nodes()} and the number of edges is: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Graph is directed\n"
     ]
    }
   ],
   "source": [
    "if nx.is_directed(G):\n",
    "    print(\"The Graph is directed\")\n",
    "else:\n",
    "    print(\"The Graph is undirected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the directed graph to understand if the graph is sparse or not, we should use this formula:\n",
    "\n",
    "$D = \\frac{|E|}{|V|(|V|-1)}$\n",
    "\n",
    "a dense graph is a graph in which the number of edges is close to the maximal number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph density is: 4.9951571365597335e-05, so the graph is sparse\n"
     ]
    }
   ],
   "source": [
    "# we can use also nx.density(G)\n",
    "D = (G.number_of_edges())/(G.number_of_nodes()*(G.number_of_nodes()-1))\n",
    "print(f\"The graph density is: {D}, so the graph is sparse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the average of link per article is.. (considering the **degree** of each node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.824674862471147"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees = dict(G.degree())\n",
    "sum(degrees.values())/float(len(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the result presents above include in_degree and out_degree of a graph. We can consider also the in_degree and out_degree formula. But, you could use also the native function of networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the indegree = 4.912337431235573 and the outdegree = 4.912337431235573\n"
     ]
    }
   ],
   "source": [
    "indegree = sum(dict(G.in_degree()).values())/float(len(G))\n",
    "outdegree = sum(dict(G.out_degree()).values())/float(len(G))\n",
    "print(f\"the indegree = {indegree} and the outdegree = {outdegree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the **nodes degree distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(nx.degree(G))\n",
    "\n",
    "NodeDistro = pd.DataFrame()\n",
    "\n",
    "NodeDistro['node'] = degrees.keys()\n",
    "NodeDistro['degree'] = degrees.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NodeDistro.groupby([NodeDistro.degree]).node.count().head(30).plot.bar(figsize=(8,4))\n",
    "    \n",
    "#create the plot\n",
    "plt.grid()\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Number of Nodes')\n",
    "plt.title('Nodes degree distribution')\n",
    "plt.grid(b=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = list(edges['source'])\n",
    "dests = list(edges['dest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose in input a page v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a node to start the BFS: 1663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1663"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = int(input(\"Choose a node to start the BFS: \"))\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of clicks d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a number of clicks: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = int(input(\"Choose a number of clicks: \"))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(G):\n",
    "    nodes = list(G.nodes()) # return the list of nodes\n",
    "    dist = [float('inf') for x in range(len(nodes))] # initialize the distance to inf in order to avoid the distance = 0, that means other thing\n",
    "    visited = [False for x in range(len(nodes))] # initialize the visited = False\n",
    "    return nodes, dist, visited\n",
    "\n",
    "def BFS(G, v, d):\n",
    "    nodes, dist, visited = initialization(G)\n",
    "    \n",
    "    queue = [] # create queue for BFS\n",
    "    \n",
    "    # start BFS\n",
    "    queue.append(v)\n",
    "    visited[nodes.index(v)] = True\n",
    "    dist[nodes.index(v)] = 0\n",
    "    \n",
    "    i = 0\n",
    "    while queue and i <= d:\n",
    "        s = queue.pop(0)\n",
    "        \n",
    "        for neigh in nx.neighbors(G, s):\n",
    "            if visited[nodes.index(neigh)] == False:\n",
    "                visited[nodes.index(neigh)] = True\n",
    "                dist[nodes.index(neigh)] = dist[nodes.index(s)] + 1\n",
    "                queue.append(neigh)\n",
    "        i+=1\n",
    "    dist = list(filter(lambda a: a != float('inf'), dist))\n",
    "        \n",
    "    return dist, nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the set of all pages that you can achieve with 2 are ['Stu Phillips (composer)']\n"
     ]
    }
   ],
   "source": [
    "dist, nodes = BFS(G, v, d)\n",
    "indices = [i for i, x in enumerate(dist) if x == d]\n",
    "nodes = [pages_names.loc[str(x), \"name\"] for i, x in enumerate(nodes) if i in indices]\n",
    "print(f\"the set of all pages that you can achieve with {d} are {nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "returns the minimum number of clicks required to reach all pages in p, starting from the page v, corresponding to the most central article, according to the in-degree centrality, in C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg = list(new_categories[\"category\"])\n",
    "pg_lst = list(new_categories[\"pages list\"])\n",
    "\n",
    "union_lst = [ [x, list(map(int,pg_lst[i]))] for i, x in enumerate(ctg) ]\n",
    "\n",
    "my_dict = {x[0]: x[1] for x in union_lst}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose randomly the category in order to find the minimum number of clicks to achieve all nodes in one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Year_of_birth_missing'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = random.sample(my_dict.keys(), 1)[0]\n",
    "cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the subgraph of G interesting to the selected category chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of pages are 1453 and the number of edges are 725\n"
     ]
    }
   ],
   "source": [
    "new_cat = G.subgraph(my_dict[cat])\n",
    "print(f\"the number of pages are {len(new_cat)} and the number of edges are {len(new_cat.edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the node most centered in the graph is.. with the in-degree centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "indegree_node = { node: new_cat.in_degree(node) for node in new_cat.nodes if new_cat.in_degree(node) != 0 } # is only to check the max value linked, i don't consider the node without edges setted with inf\n",
    "indegree_node = dict(sorted(indegree_node.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the node 1143580 is the most centered with 6 edges\n"
     ]
    }
   ],
   "source": [
    "min_val = max(indegree_node.items(), key=lambda x: x[1])\n",
    "source = min_val[0]\n",
    "print(f\"the node {min_val[0]} is the most centered with {min_val[1]} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call and calculate the BFS for all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call different_bfs() and create the matrix of distances from v to all edges, so..\n",
    "dict_allbfs = { k: { x: float(\"inf\")  for x in my_dict[cat] } for k in my_dict[cat] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1453/1453 [00:00<00:00, 90775.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for node in tqdm(dict_allbfs):\n",
    "    distances = different_bfs(new_cat, node)\n",
    "    for val in distances:\n",
    "        dict_allbfs[node][val] = distances[val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the new graph directed and well weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cat_W = nx.DiGraph(directed=True)\n",
    "\n",
    "for node in dict_allbfs:\n",
    "    G_cat_W.add_node(node, name = pages_names.loc[str(node), 'name'])\n",
    "    for edge in dict_allbfs[node]:\n",
    "        if (dict_allbfs[node][edge] != float(\"inf\")) and (dict_allbfs[node][edge] != 0):\n",
    "            G_cat_W.add_edge(node, edge, weight=dict_allbfs[node][edge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NO EXECUTE THIS... we have more nodes...\n",
    "labels = nx.get_edge_attributes(G_cat_W,'weight')\n",
    "pos=nx.kamada_kawai_layout(G_cat_W) # pos = nx.nx_agraph.graphviz_layout(G)\n",
    "plt.figure(3,figsize=(15, 10))\n",
    "nx.draw_networkx(G_cat_W, pos, node_color='#03b4d9')\n",
    "nx.draw_networkx_edge_labels(G_cat_W, pos, with_labels=True, edge_labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neigh(G, v):\n",
    "    queue = []\n",
    "    queue.append(v)\n",
    "    \n",
    "    explored = {}\n",
    "    explored[v] = 0\n",
    "    while queue:\n",
    "        s = queue.pop(0)\n",
    "\n",
    "        near_dists = []\n",
    "        for neigh in nx.neighbors(G, s):\n",
    "            near_dists.append([neigh, G[s][neigh]['weight']])\n",
    "        \n",
    "        if near_dists:\n",
    "            near_neigh = sorted(near_dists, key = lambda x: x[1])[0][0]\n",
    "            if near_neigh not in explored:\n",
    "                explored[neigh] = G[s][neigh]['weight']\n",
    "                queue.append(near_neigh)\n",
    "    \n",
    "    if len(explored) != len(G.nodes):\n",
    "        return \"we can't achieve all pages, so.. NOT POSSIBLE!\"\n",
    "    else:\n",
    "        return f\"we need a minimum of {sum(explored.values())} steps to achieve all pages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"we can't achieve all pages, so.. NOT POSSIBLE!\""
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neigh(G_cat_W, source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that, given an arbitrary category C0 as input, returns the list of remaning categories sorted by their distance from C0. In particular, the distance between two categories is defined as\n",
    "\n",
    "distance(C0, Ci) = median(ShortestPath(C0, Ci))\n",
    "\n",
    "where ShortestPath(C0, Ci) is the set of shortest paths from each pair of nodes in the two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert the first category: Debut_albums\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Debut_albums'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c0 = str(input(\"Insert the first category: \"))\n",
    "c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_bfs(G, v):\n",
    "    queue = [] # create queue for BFS\n",
    "    \n",
    "    # start BFS\n",
    "    queue.append(v)\n",
    "    distances = {}\n",
    "    distances[v] = 0\n",
    "    \n",
    "    while queue:\n",
    "        s = queue.pop(0)\n",
    "        \n",
    "        for neigh in nx.neighbors(G, s):\n",
    "            if neigh not in distances:\n",
    "                distances[neigh] = distances[s] + 1\n",
    "                queue.append(neigh)\n",
    "                \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2553/2553 [06:06<00:00,  6.97it/s]\n",
      "21it [02:03,  5.89s/it]\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "ctg = list(new_categories[\"category\"])\n",
    "pg_lst = list(new_categories[\"pages list\"])\n",
    "union_lst = [ [x, list(map(int,pg_lst[i]))] for i, x in enumerate(ctg) ]\n",
    "my_dict = {x[0]: x[1] for x in union_lst}\n",
    "\n",
    "list_c0 = my_dict[c0]\n",
    "my_distances_bfs = {}\n",
    "for node in tqdm(list_c0):\n",
    "    my_distances_bfs[node] = different_bfs(G, node)\n",
    "\n",
    "medians = []\n",
    "for i, ct in tqdm(enumerate(ctg)):\n",
    "    values_lists = []\n",
    "    if ct != c0: \n",
    "        list_c_i = my_dict[ct]\n",
    "        for node_x in list_c0:\n",
    "            for node_y in list_c_i: \n",
    "                if node_y in my_distances_bfs[node_x]:\n",
    "                    values_lists.append(my_distances_bfs[node_x][node_y])\n",
    "                else:\n",
    "                    values_lists.append(float(\"inf\"))\n",
    "        medians.append(statistics.median(values_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists2 = medians.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_dist_idx = [ [i, int(x)] for i, x in enumerate(dists2) if x != float(\"inf\") ]\n",
    "union_dist_idx = sorted(union_dist_idx, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American_television_actors</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_film_actors</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English-language_films</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American_films</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black-and-white_films</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Members_of_the_United_Kingdom_Parliament_for_E...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rivers_of_Romania</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            category  distance\n",
       "0                         American_television_actors         6\n",
       "1                               American_film_actors         6\n",
       "2                             English-language_films         6\n",
       "3                                     American_films         6\n",
       "4                              Black-and-white_films         7\n",
       "5  Members_of_the_United_Kingdom_Parliament_for_E...         9\n",
       "6                                  Rivers_of_Romania        11"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_cat0 = pd.DataFrame()\n",
    "distance_cat0[\"category\"] = [ new_categories.loc[x[0], \"category\"] for x in union_dist_idx ]\n",
    "distance_cat0[\"distance\"] = [ x[1] for x in union_dist_idx ]\n",
    "distance_cat0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that sorts the categories in the graph according to their PageRank (PR). For this task you need to model the network of categories such that you can apply the PR algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def PageRank(G, d = 0.85, max_iter = 100):\n",
    "    probs_node = { x: 1 / len(G) for x in G.nodes }                                                                                             # create dict of uniform probs for each page\n",
    "    out_degrees = { x: G.out_degree(x) if G.out_degree(x) != 0 else len(G) for x in G.nodes }                                                   # create dict of uniform out_degrees for each page and for a page with noone outlinks our choice is uniformly at all pages present, so consider the length of the graph \n",
    "    \n",
    "    new_probs_node = probs_node.copy()                                                                                                          # save each new iteration considering always the old probabilities\n",
    "                                                                                                                                                # the optimal way to choose the correct number of iterations\n",
    "    for _ in tqdm(range(max_iter)):                                                                                                             # the algorithm iterate to achieve the best predictive socre  \n",
    "        for p_x in new_probs_node:                                                                                                              # catch each page in order to update the probabilities                            \n",
    "            ratios_sum = sum([ probs_node[neigh] / out_degrees[neigh] for neigh in nx.neighbors(G, p_x) ])                                      # increase the rank, check if the neighbors has outgoing links, if it not go forward to the next neighbor\n",
    "            new_probs_node[p_x] = ( ( 1 - d ) / len(G) ) + ( d * ratios_sum )                                                                   # then update the value for the i-th node\n",
    "        \n",
    "            probs_node = new_probs_node.copy()\n",
    "    \n",
    "    return new_probs_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful create a dict\n",
    "refer_dt = categories[categories['Category'].isin(list(new_categories[\"category\"]))]\n",
    "lst_category = list(refer_dt['Category'])\n",
    "\n",
    "lst_pages = [ set(map(int, lst_pg )) for lst_pg in list(refer_dt[\"Pages List\"]) ]\n",
    "my_dict = { cat: lst_pages[i] for i, cat in enumerate(lst_category) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new graph of categories and inserts the node as one category\n",
    "new_G = nx.DiGraph(directed=True)\n",
    "for cat in lst_category:\n",
    "    new_G.add_node(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 263.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# add edges\n",
    "for x in tqdm(my_dict):\n",
    "    for y in my_dict:\n",
    "        if (x != y and len(my_dict[x].intersection(my_dict[y])) > 0):\n",
    "            new_G.add_edge(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a reasonable situation because the categories haven't any nodes connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 16708.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9190476190476178"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_PageRank = PageRank(new_G)\n",
    "sum(tot_PageRank.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(nx.pagerank(new_G, alpha = 0.85).values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
